{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_inception_v2_shopee_image_classification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMbufhiZZ3jM/8jAaSqTom9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhhanifra/Shoppee-product-Classification-Challenge/blob/main/resnet_inception_v2_shopee_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXiY0-nLpOh8"
      },
      "source": [
        "# InceptionResNetV2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVmFjCxBpegF",
        "outputId": "c972b8a7-6bc1-4adc-e726-f5fb72946e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "#open drive\n",
        "drive.mount('/content/gdrive')\n",
        "#unzip data\n",
        "with zipfile.ZipFile('/content/gdrive/My Drive/Copy of shopee-product-detection-dataset.zip') as zip_file:\n",
        "  zip_file.extractall('/content/dataset')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7Izz0ovpjTd"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Input, Activation, Dropout, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import InceptionResNetV2\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCzRtAibpzWk"
      },
      "source": [
        "# freeze layer 0 to layer l, and unfreeze layer l+1 up until layer L\n",
        "def set_trainable(model, transfer_criteria = 'finetune_all', print_details = False):\n",
        "\n",
        "  #freeze all layers\n",
        "  if transfer_criteria == 'freeze_all':\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = False\n",
        "      \n",
        "      if print_details == True:\n",
        "        print('layer name: {}, trainable {}'.format(layer.name, layer.trainable))\n",
        "\n",
        "  #finetune all layers\n",
        "  elif transfer_criteria == 'finetune_all':\n",
        "    for layer in model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "      if print_details == True:\n",
        "        print('layer name: {}, trainable {}'.format(layer.name, layer.trainable))\n",
        "  \n",
        "  #set layers trainable from the specified layer up to the last layer\n",
        "  else:\n",
        "    trainable_condition = False\n",
        "    for layer in model.layers:\n",
        "      if layer.name == transfer_criteria:\n",
        "        trainable_condition = True\n",
        "      layer.trainable = trainable_condition\n",
        "\n",
        "      if print_details == True:\n",
        "        print('layer name: {}, trainable {}'.format(layer.name, layer.trainable))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWjecqulp1m-"
      },
      "source": [
        "def plt_model(model):\n",
        "  plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "def create_transfer_learning_model(transferred_model):\n",
        "  \n",
        "  i = tf.keras.layers.Input([224, 224, 3], dtype = tf.uint8)\n",
        "  _i = tf.cast(i, tf.float32)\n",
        "  _i = tf.keras.applications.inception_resnet_v2.preprocess_input(_i)\n",
        "  \n",
        "  core = transferred_model(_i) \n",
        "  x = layers.GlobalAveragePooling2D()(core)\n",
        "  x = Dense(42, activation='softmax')(x)\n",
        "  model = Model(inputs=[i], outputs=[x])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4n5j2Evp3fL"
      },
      "source": [
        "model_name = 'resnet_inception_v2_cont_1.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_Ebgxj9p8WD"
      },
      "source": [
        "resnet_inception = InceptionResNetV2(include_top=False,\n",
        "                                     weights=\"imagenet\",\n",
        "                                     input_tensor=None,\n",
        "                                     input_shape = (224, 224, 3),\n",
        "                                     pooling=None)\n",
        "\n",
        "set_trainable(resnet_inception, transfer_criteria = 'block8_8_mixed', print_details = True)\n",
        "model = create_transfer_learning_model(resnet_inception)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh-3QY7dRYyD"
      },
      "source": [
        "# model_path = '/content/gdrive/My Drive/resnet_inception_v2/resnet_inception_v2/resnet_inception_v2.h5'\n",
        "# model = tf.keras.models.load_model(model_path)\n",
        "# set_trainable(model.layers[4], transfer_criteria = 'block8_8_mixed', print_details = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N5BtAhKTtIm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WH94FRVpq07k"
      },
      "source": [
        "#-----hyperparams\n",
        "EPOCHS = 7\n",
        "BATCH_SIZE = 64\n",
        "learning_rate = 0.00005"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmxaWmZFsaUW"
      },
      "source": [
        "class LossHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs):\n",
        "        self.epoch = 0 \n",
        "        self.per_batch_losses = []\n",
        "        self.per_batch_acc = []\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        \n",
        "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
        "        self.per_batch_acc.append(logs.get('accuracy'))\n",
        "        \n",
        "    def on_epoch_begin(self, batch, logs):\n",
        "        self.epoch = self.epoch + 1\n",
        "        # if self.epoch == 5:\n",
        "        #   model.optimizer.lr = 0.0003\n",
        "        #   print('proceed with smaller learning rate...\\n')\n",
        "        # if self.epoch == 8:\n",
        "        #   model.optimizer.lr = 0.0001\n",
        "        # if self.epoch == 10:\n",
        "        #   print('proceed with even smaller learning rate...\\n')\n",
        "        #   model.optimizer.lr = 0.00005\n",
        "\n",
        "\n",
        "step_hist = LossHistory()\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', \n",
        "                   mode='min', \n",
        "                   verbose=1, \n",
        "                   patience=30)\n",
        "\n",
        "mc = ModelCheckpoint(model_name, \n",
        "                     monitor='val_accuracy', \n",
        "                     mode='max', \n",
        "                     verbose=1,\n",
        "                     save_best_only=True)\n",
        "\n",
        "opt = keras.optimizers.Nadam(lr = learning_rate)\n",
        "model.compile(optimizer= opt, \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV5yjXAIs3T8",
        "outputId": "ecfa8542-effa-4141-a625-f908726c3a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_dir = '/content/dataset/train/train'\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(width_shift_range= 0.2,\n",
        "                             height_shift_range = 0.2,\n",
        "                             horizontal_flip = True,\n",
        "                             zoom_range=0.15,\n",
        "                             shear_range = 15,\n",
        "                             rotation_range = 20, \n",
        "                             validation_split = 0.1,\n",
        "                             brightness_range=[0.2,1.0])\n",
        "\n",
        "data_flow_train = datagen.flow_from_directory(train_dir,\n",
        "                                        target_size= (224,224), \n",
        "                                        class_mode = 'categorical',\n",
        "                                        batch_size = BATCH_SIZE, \n",
        "                                        subset = 'training',\n",
        "                                        seed=12)\n",
        "\n",
        "data_flow_val = datagen.flow_from_directory(train_dir,\n",
        "                                        target_size= (224,224), \n",
        "                                        class_mode = 'categorical',\n",
        "                                        batch_size = BATCH_SIZE, \n",
        "                                        subset = 'validation',\n",
        "                                        seed=12)\n",
        "m_train = data_flow_train.samples\n",
        "m_val = data_flow_val.samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 94869 images belonging to 42 classes.\n",
            "Found 10523 images belonging to 42 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKUv29fJtKRZ"
      },
      "source": [
        "def save_model_to_drive(model_name):\n",
        "  model_name_string = model_name.split('.')[0]\n",
        "  destination = '/content/gdrive/My Drive/resnet_inception_v2/{}'.format(model_name_string)\n",
        "  if not os.path.exists(destination):\n",
        "      os.makedirs(destination)\n",
        "\n",
        "  source_pretrained = '/content/{}'.format(model_name)\n",
        "\n",
        "  shutil.move(source_pretrained, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeBSds5uuPhZ",
        "outputId": "a647eb80-6f91-430c-9e4e-3540f9c26704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "try:\n",
        "  history = model.fit(data_flow_train, \n",
        "                      validation_data= data_flow_val,\n",
        "                      validation_steps = 10, \n",
        "                      steps_per_epoch = m_train/BATCH_SIZE, \n",
        "                      epochs = EPOCHS, \n",
        "                      callbacks=[es, mc, step_hist])\n",
        "except:\n",
        "  print('something went wrong during training!, saving the last model to drive')\n",
        "  save_model_to_drive(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "1483/1482 [==============================] - ETA: 0s - loss: 0.7115 - accuracy: 0.7887\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72344, saving model to resnet_inception_v2_cont_1.h5\n",
            "1483/1482 [==============================] - 2081s 1s/step - loss: 0.7115 - accuracy: 0.7887 - val_loss: 1.0512 - val_accuracy: 0.7234\n",
            "Epoch 2/7\n",
            "1483/1482 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.8028\n",
            "Epoch 00002: val_accuracy improved from 0.72344 to 0.72969, saving model to resnet_inception_v2_cont_1.h5\n",
            "1483/1482 [==============================] - 2083s 1s/step - loss: 0.6643 - accuracy: 0.8028 - val_loss: 1.0253 - val_accuracy: 0.7297\n",
            "Epoch 3/7\n",
            "1483/1482 [==============================] - ETA: 0s - loss: 0.6384 - accuracy: 0.8103\n",
            "Epoch 00003: val_accuracy did not improve from 0.72969\n",
            "1483/1482 [==============================] - 2084s 1s/step - loss: 0.6384 - accuracy: 0.8103 - val_loss: 1.0707 - val_accuracy: 0.7234\n",
            "Epoch 4/7\n",
            "1483/1482 [==============================] - ETA: 0s - loss: 0.6150 - accuracy: 0.8146\n",
            "Epoch 00004: val_accuracy did not improve from 0.72969\n",
            "1483/1482 [==============================] - 2078s 1s/step - loss: 0.6150 - accuracy: 0.8146 - val_loss: 0.9703 - val_accuracy: 0.7219\n",
            "Epoch 5/7\n",
            "1483/1482 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.8203\n",
            "Epoch 00005: val_accuracy did not improve from 0.72969\n",
            "1483/1482 [==============================] - 2066s 1s/step - loss: 0.5961 - accuracy: 0.8203 - val_loss: 1.1161 - val_accuracy: 0.7203\n",
            "Epoch 6/7\n",
            "1483/1482 [==============================] - ETA: 0s - loss: 0.5804 - accuracy: 0.8241\n",
            "Epoch 00006: val_accuracy did not improve from 0.72969\n",
            "1483/1482 [==============================] - 2066s 1s/step - loss: 0.5804 - accuracy: 0.8241 - val_loss: 1.0240 - val_accuracy: 0.7172\n",
            "Epoch 7/7\n",
            "1006/1482 [===================>..........] - ETA: 10:52 - loss: 0.5706 - accuracy: 0.8271"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc2lqtxZuQJo"
      },
      "source": [
        "try:\n",
        "  save_model_to_drive(model_name)\n",
        "except:\n",
        "  print('ERROR ! could not find the saved model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIFJPHtMuTDy"
      },
      "source": [
        "def learning_history_recap(model_name, history, step_hist):\n",
        "  df_history = pd.DataFrame(history.history)\n",
        "  per_batch_hist = {'loss': step_hist.per_batch_losses,\n",
        "                    'acc': step_hist.per_batch_acc}\n",
        "  df_perbatch_hist = pd.DataFrame(per_batch_hist)\n",
        "  \n",
        "  df_history.to_csv('{}_per_epoch_recap.csv'.format(model_name),index = False)\n",
        "  df_perbatch_hist.to_csv('{}_per_batch_recap.csv'.format(model_name),index = False)\n",
        "\n",
        "  return (df_history, df_perbatch_hist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koy-5XzCuUy8"
      },
      "source": [
        "model_name_string = model_name.split('.')[0]\n",
        "destination = '/content/gdrive/My Drive/resnet_inception_v2/{}'.format(model_name_string)\n",
        "\n",
        "learning_recaps = learning_history_recap(model_name, history, step_hist)\n",
        "history_source = '/content/{}_per_epoch_recap.csv'.format(model_name)\n",
        "history_per_batch_source = '/content/{}_per_batch_recap.csv'.format(model_name)\n",
        "\n",
        "shutil.move(history_source, destination)\n",
        "shutil.move(history_per_batch_source, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFFk6pruuWm6"
      },
      "source": [
        "plt.figure(figsize = (15,8))\n",
        "plt.plot(step_hist.per_batch_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize = (15,8))\n",
        "plt.plot(step_hist.per_batch_acc)\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt-xW8r8uyWt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}